{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Solution: Early Stopping and Training Monitoring\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You've recently joined HealthTech Analytics, a healthcare AI startup that's developing systems to predict patient readmission risk based on electronic health records. As a junior data scientist, you've been tasked with implementing a neural network model, which has been showing promising results but has inconsistent performance.\n",
    "\n",
    "Your manager explains that the model sometimes performs well, but other times it overfits to training data or fails to converge properly. She suspects that proper training monitoring and early stopping strategies might solve these issues, making the model more reliable for clinical applications.\n",
    "\n",
    "The Chief Data Officer has emphasized that the company can't afford to waste computational resources on models that aren't learning effectively, and clinical staff need stable, reliable predictions. You'll need to implement proper training monitoring and callbacks to ensure the model trains efficiently and generalizes well to new patient data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Import Libraries and Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup compatible TensorFlow environment\n",
    "import sys\n",
    "import os\n",
    "# Downgrade NumPy to a 1.x version compatible with TensorFlow\n",
    "!{sys.executable} -m pip install \"numpy<2.0,>=1.24.0\" --upgrade --no-cache-dir\n",
    "# Install TensorFlow 2.14, which works with NumPy 1.x\n",
    "!{sys.executable} -m pip install \"tensorflow==2.14.0\" --upgrade --no-cache-dir\n",
    "# Restart the kernel automatically to apply changes\n",
    "print(\"Restarting kernel...\")\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load and Explore Dataset\n",
    "\n",
    "The dataset contains information from diabetic patients with various features such as age, gender, lab results, medical history, and a target variable indicating whether the patient was readmitted within 30 days, after 30 days, or not at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Data\n",
    "patient_data = pd.read_csv('readmission_data.csv')\n",
    "patient_data.info()\n",
    "patient_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the dataset\n",
    "print(f\"Dataset shape: {patient_data.shape}\")\n",
    "print(f\"Readmission rate: {patient_data['readmitted'].value_counts(normalize=True)}\")\n",
    "\n",
    "# Check class balance\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='readmitted', data=patient_data)\n",
    "plt.title('Distribution of Readmissions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate out features for visualization\n",
    "num_features = patient_data.select_dtypes(include='number')\n",
    "# Irrelevant or categoricall\n",
    "num_features.drop(['encounter_id', 'patient_nbr', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id'], axis=1, inplace=True)\n",
    "\n",
    "# Look at numerical feature distributions\n",
    "for i, col in enumerate(num_features):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.histplot(data=patient_data, x=col, hue='readmitted', kde=True)\n",
    "    plt.title(f'Distribution of {col} by Readmission Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate out features for visualization\n",
    "categorical = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id']\n",
    "cat_columns = patient_data.select_dtypes(include='object')\n",
    "cat_cols = list(cat_columns.columns)\n",
    "categorical.extend(cat_cols)\n",
    "categorical.remove('readmitted')\n",
    "cat_features = patient_data[categorical]\n",
    "\n",
    "# Categorical features\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(cat_features):\n",
    "    crosstab = pd.crosstab(patient_data[col], patient_data['readmitted'], normalize='index')\n",
    "    crosstab.plot(kind='bar', stacked=True, colormap='viridis')\n",
    "    plt.title(f'{col} vs Readmission Rate')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement Baseline Model\n",
    "First you need to prepare the data for modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "# We will look to combine readmission to make this binary\n",
    "patient_data['readmitted'] = patient_data['readmitted'].map({'<30': 1, '>30': 1, 'NO': 0})\n",
    "\n",
    "# These columns hold no meaning are just unique identifiers and readmitted is our target\n",
    "cols_to_drop = ['encounter_id', 'patient_nbr', 'readmitted']\n",
    "X = patient_data.drop(cols_to_drop, axis=1)\n",
    "y = patient_data['readmitted']\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: 80% train+validation, 20% test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 75% train, 25% validation (resulting in 60% train, 20% validation, 20% test overall)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Preprocess data with Column Transformer pipeline\n",
    "# To prevent high dimenstionality we will target encode the diagnosis codes rather than one hot encode\n",
    "target_encode_cols = ['diag_1', 'diag_2', 'diag_3']\n",
    "ohe_cols = [col for col in categorical if col not in target_encode_cols]\n",
    "num_cols = num_features.columns\n",
    "\n",
    "# Create the preprocessing function\n",
    "num_pipe = Pipeline(steps=[('impute_num', SimpleImputer(strategy='median')),\n",
    "                           ('scaler', StandardScaler())])\n",
    "\n",
    "ohe_pipe = Pipeline(steps=[('impute_cat', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "                           ('ohe', OneHotEncoder(drop='first', handle_unknown='ignore'))])\n",
    "\n",
    "tarenc_pipe = Pipeline(steps=[('impute_cat', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "                              ('tar_encode', TargetEncoder(target_type='binary'))])\n",
    "\n",
    "col_trans = ColumnTransformer(transformers=[('num', num_pipe, num_cols),\n",
    "                                            ('cat', ohe_pipe, ohe_cols),\n",
    "                                            ('tar', tarenc_pipe, target_encode_cols)],\n",
    "                              remainder='passthrough')\n",
    "\n",
    "# Need to provide y_train for the target encoder\n",
    "X_train_pro = col_trans.fit_transform(X_train, y_train)\n",
    "X_val_pro = col_trans.transform(X_val)\n",
    "X_test_pro = col_trans.transform(X_test)\n",
    "\n",
    "# Convert sparse matrices to dense arrays if needed\n",
    "X_train_pro = X_train_pro.toarray() if hasattr(X_train_pro, \"toarray\") else X_train_pro\n",
    "X_val_pro   = X_val_pro.toarray() if hasattr(X_val_pro, \"toarray\") else X_val_pro\n",
    "X_test_pro  = X_test_pro.toarray() if hasattr(X_test_pro, \"toarray\") else X_test_pro\n",
    "\n",
    "\n",
    "print(f\"Training set: {X_train_pro.shape} samples\")\n",
    "print(f\"Validation set: {X_val_pro.shape} samples\")\n",
    "print(f\"Test set: {X_test_pro.shape} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline with two hidden layers, use the relu activation function, select an appropriate number of nodes (64, 32)\n",
    "# Don't forget your output layer for binary classification\n",
    "def create_baseline_model(input_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Input(shape=(input_dim)))\n",
    "    #Hidden layers\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        # Use Adam\n",
    "        optimizer=Adam(),\n",
    "        # Select appropriate loss for binary classification\n",
    "        loss='binary_crossentropy',\n",
    "        # Evaluate based on recall\n",
    "        metrics=[tf.keras.metrics.Recall(name='recall')] # important in healthcare\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and train the baseline model\n",
    "baseline_model = create_baseline_model(X_train_pro.shape[1])\n",
    "baseline_model.summary()\n",
    "\n",
    "# Train the model without any callbacks\n",
    "baseline_history = baseline_model.fit(\n",
    "    X_train_pro, y_train,\n",
    "    epochs=50,  # Train for a fixed number of epochs\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_pro, y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Visualize Training and Validation curves\n",
    "Important to visualize our training curves in order to understand model limitations and adapt the next iteration. Particularly important to understand the models bias and variance (over/under fitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the baseline model on testing data\n",
    "baseline_test_loss, baseline_test_recall = baseline_model.evaluate(X_test_pro, y_test, verbose=0)\n",
    "print(f\"Baseline Test Recall: {baseline_test_recall:.4f}\")\n",
    "\n",
    "# Plot the training and validation loss/accuracy curves\n",
    "def plot_training_history(history, title=''):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title(f'{title} - Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot recall\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['recall'], label='Train Recall')\n",
    "    plt.plot(history.history['val_recall'], label='Val Recall')\n",
    "    plt.title(f'{title} - Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot baseline model training history\n",
    "plot_training_history(baseline_history, title='Baseline Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Implement Callbacks for Monitoring and Early Stopping\n",
    "\n",
    "Clear sign of model overfitting and gradient problems. Now, let's implement callbacks to monitor training and prevent overfitting. We will also provide a more complex network to attempt to address the overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Implement ModelCheckpoint callback to save the best model\n",
    "checkpoint_filepath = './best_model.h5'\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Implement TensorBoard callback for visualization\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "# Don't change this one\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,        # Reduce learning rate by 80%\n",
    "    patience=3,        # Wait 5 epochs of no improvement\n",
    "    min_lr=0.000001,    # Don't go below this learning rate\n",
    "    verbose=1          # Print when learning rate changes\n",
    ")\n",
    "\n",
    "# Combine all callbacks into a list\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    model_checkpoint,\n",
    "    tensorboard_callback,\n",
    "    reduce_lr\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Create an improved model with gradient problem mitigation strategies and train with callbacks\n",
    "def create_improved_model(input_dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First layer\n",
    "    model.add(Input((input_dim,)))\n",
    "    model.add(Dense(64))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.2))  \n",
    "    \n",
    "    # Second layer\n",
    "    model.add(Dense(32))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Use Adam optimizer with gradient clipping\n",
    "    optimizer = Adam(learning_rate=0.001, clipvalue=.5)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.Recall()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile the improved model\n",
    "improved_model = create_improved_model(X_train_pro.shape[1])\n",
    "improved_model.summary()\n",
    "\n",
    "# Ensure targets are float32\n",
    "y_train = y_train.astype('float32')\n",
    "y_val = y_val.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "# Compile the model properly\n",
    "improved_model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[Recall()]  # ensures 'recall' appears in history\n",
    ")\n",
    "\n",
    "# Train with callbacks\n",
    "improved_history = improved_model.fit(\n",
    "    X_train_pro, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_pro, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Analyze Training Results\n",
    "Again, it is always important to look at curves. Here we should see way less overfitting and platued losses which tell us the model has gone about as far as it can go with the data at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training history with early stopping\n",
    "plot_training_history(improved_history, title='Improved Model with Callbacks')\n",
    "\n",
    "# Load the best model saved by ModelCheckpoint\n",
    "best_model = load_model(checkpoint_filepath)\n",
    "\n",
    "# Evaluate the final improved model\n",
    "improved_test_loss, improved_test_recall = improved_model.evaluate(X_test_pro, y_test, verbose=1)\n",
    "print(f\"Improved Model (Final) Test Recall: {improved_test_recall:.4f}\")\n",
    "\n",
    "# Evaluate the best model (saved by checkpoint)\n",
    "best_test_loss, best_test_recall = best_model.evaluate(X_test_pro, y_test, verbose=1)\n",
    "print(f\"Best Model (Checkpoint) Test Recall: {best_test_recall:.4f}\")\n",
    "\n",
    "# Compare with baseline\n",
    "print(f\"Baseline Test Recall: {baseline_test_recall:.4f}\")\n",
    "print(f\"Early Stopping activated at epoch {len(improved_history.history['loss'])} of 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Launch TensorBoard\n",
    "%tensorboard --logdir=logs/fit\n",
    "\n",
    "# Note: TensorBoard output will appear in the notebook\n",
    "# We can examine histograms of weights and gradients, model graph,\n",
    "# and other useful visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training complex machine learning models, the relationship between model complexity and data quality is crucial. Even the most sophisticated neural network architecture can plateau if the loss stops decreasing, indicating that the model has reached the limits of what it can learn from the available data. At this point, rather than adding more layers or parameters, the focus should shift to improving data quality, diversity, and relevance to the specific task. Better data—whether that means more accurate labels, more representative samples, or enhanced feature engineering—often proves more valuable than increased model complexity for breaking through performance plateaus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Reflection and Documentation\n",
    "\n",
    "### Question 1: How did early stopping affect the training process and final model performance?\n",
    "\n",
    "Early stopping helped the model avoid overfitting by stopping the training as soon as it stopped improving. It also saved on computation time by preventing the model from having to iterate through all 100 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: What patterns did you observe in the training and validation curves?\n",
    "\n",
    "As the number of epochs increased in the model, the training error decreased while the validation error increased, signifying overfitting. Early stopping enabled the model to optimize both values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: In a healthcare context like this one, why is it particularly important to prevent overfitting?\n",
    "\n",
    "Overfitting would lead to more predictions based on anomalies in the training data instead of real life trends. In a healthcare context that would lead to missed warnings for patients at higher risk in addition to needless time and resources being spent on low risk patients.\n",
    "\n",
    "### Question 4: How would you explain the benefits of your monitoring approach to non-technical healthcare staff?\n",
    "\n",
    "This model is able to recognize trends in patient information instead of only memorizing past data. It uses processes that can track progress on it's own learning so that it is able to optimize its predictive ability. These processes function in order to better identify risk and avoid false alarms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Implemented Techniques\n",
    "\n",
    "In this lab, we've implemented and demonstrated several key techniques for improving neural network training:\n",
    "\n",
    "1. **Early Stopping**: Automatically halts training when validation performance stops improving, preventing overfitting and saving computational resources.\n",
    "\n",
    "2. **Model Checkpointing**: Saves the best-performing model during training, ensuring we retain the optimal weights even if training continues past the ideal point.\n",
    "\n",
    "3. **Training Visualization**: Using TensorBoard and custom plotting functions to monitor and interpret the training process in real-time.\n",
    "\n",
    "4. **BatchNormalization**: Stabilizes the distribution of layer inputs during training, helping to prevent vanishing/exploding gradients.\n",
    "\n",
    "5. **Gradient Clipping**: Limits the size of gradient updates to prevent unstable training.\n",
    "\n",
    "6. **Advanced Activation Functions**: Using LeakyReLU instead of standard ReLU to prevent \"dead neurons\" and improve gradient flow.\n",
    "\n",
    "8. **Dropout**: Randomly deactivating neurons during training to prevent overfitting and improve generalization.\n",
    "\n",
    "By combining these techniques, we were able to improve model performance and training stability if only minorly, resulting in a more reliable patient readmission prediction model that would perform better in real-world healthcare settings. Ultimately, because our final model is accounting for potential issues and still not performing as well as we hoped, it becomes a matter of needing better and more data to predict readmission.\n",
    "\n",
    "These monitoring and optimization techniques are applicable across a wide range of deep learning applications, not just healthcare, and should be considered essential components of any robust deep learning workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
